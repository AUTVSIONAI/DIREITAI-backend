const { supabase, adminSupabase } = require('../config/supabase');

// Fun√ß√£o para analisar metadados de imagem sem enviar o conte√∫do completo
function analyzeImageMetadata(dataUrl) {
  try {
    // Extrair informa√ß√µes do data URL
    const [header, base64Data] = dataUrl.split(',');
    const mimeMatch = header.match(/data:image\/(\w+)/);
    const format = mimeMatch ? mimeMatch[1].toUpperCase() : 'UNKNOWN';
    
    // Calcular tamanho aproximado
    const sizeBytes = Math.round((base64Data.length * 3) / 4);
    const sizeKB = Math.round(sizeBytes / 1024);
    const size = sizeKB > 1024 ? `${Math.round(sizeKB / 1024)}MB` : `${sizeKB}KB`;
    
    // Verificar se cont√©m indicadores de C2PA nos metadados
    // C2PA geralmente aparece em formatos como JPEG, PNG, WebP
    const hasC2PA = base64Data.includes('c2pa') || 
                    base64Data.includes('C2PA') || 
                    base64Data.includes('contentauthenticity') ||
                    header.includes('c2pa');
    
    return {
      format,
      size,
      hasC2PA,
      sizeBytes
    };
  } catch (error) {
    console.error('Erro ao analisar metadados da imagem:', error);
    return {
      format: 'UNKNOWN',
      size: 'UNKNOWN',
      hasC2PA: false,
      sizeBytes: 0
    };
  }
}

// Limites por plano
const PLAN_LIMITS = {
  gratuito: -1, // ilimitado para chat b√°sico
  cidadao: -1, // ilimitado para chat
  premium: -1, // ilimitado para chat
  pro: -1, // ilimitado para chat
  elite: -1 // ilimitado para chat
};

// Verificar limites de uso do usu√°rio
async function checkUserLimits(userId, userPlan = 'gratuito') {
  try {
    const today = new Date().toISOString().split('T')[0];
    
    // Contar conversas de hoje
    // Usando adminSupabase para contornar pol√≠ticas RLS
    const { count: todayUsage, error } = await adminSupabase
      .from('ai_conversations')
      .select('*', { count: 'exact', head: true })
      .eq('user_id', userId)
      .gte('created_at', today + 'T00:00:00.000Z')
      .lt('created_at', today + 'T23:59:59.999Z');

    if (error) {
      console.error('Error checking user limits:', error);
      return {
        canUse: false,
        used: 0,
        limit: 0,
        remaining: 0
      };
    }

    const limit = PLAN_LIMITS[userPlan] || PLAN_LIMITS.gratuito;
    const used = todayUsage || 0;
    
    // Se o limite √© -1, significa ilimitado
    if (limit === -1) {
      return {
        canUse: true,
        used,
        limit: -1,
        remaining: -1 // -1 indica ilimitado
      };
    }
    
    const remaining = Math.max(0, limit - used);
    const canUse = used < limit;

    return {
      canUse,
      used,
      limit,
      remaining
    };
  } catch (error) {
    console.error('Error in checkUserLimits:', error);
    return {
      canUse: false,
      used: 0,
      limit: 0,
      remaining: 0
    };
  }
}

// Lista de modelos gratuitos da OpenRouter para fallback inteligente
const FREE_OPENROUTER_MODELS = [
  'meta-llama/llama-3.3-70b-instruct:free',
  'google/gemini-2.0-flash-exp:free',
  'nvidia/llama-3.1-nemotron-ultra-253b-v1:free',
  'google/gemma-3-27b-it:free',
  'qwen/qwq-32b:free',
  'deepseek/deepseek-chat-v3-0324:free',
  'google/gemini-2.5-pro-exp-03-25:free',
  'mistralai/mistral-small-3.1-24b-instruct:free',
  'meta-llama/llama-4-maverick:free',
  'meta-llama/llama-4-scout:free'
];

// Fun√ß√£o para chamar OpenRouter com modelo espec√≠fico
async function callOpenRouterModel(message, systemPrompt, model) {
  const openRouterKey = process.env.OPENROUTER_API_KEY;
  
  if (!openRouterKey) {
    throw new Error('OPENROUTER_API_KEY n√£o configurada');
  }

  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 25000); // 25 segundos timeout

  try {
    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openRouterKey}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': 'https://direitai.com',
        'X-Title': 'DireitaGPT - Assistente IA Conservador'
      },
      body: JSON.stringify({
        model: model,
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: message
          }
        ],
        max_tokens: 500,
        temperature: 0.7
      }),
      signal: controller.signal
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      const errorData = await response.text();
      console.error(`Erro no modelo ${model}:`, response.status, errorData);
      throw new Error(`OpenRouter API Error: ${response.status}`);
    }

    const data = await response.json();
    return {
      content: data.choices[0]?.message?.content || 'Desculpe, n√£o consegui processar sua mensagem.',
      tokensUsed: data.usage?.total_tokens || 100,
      model: model,
      provider: 'openrouter',
      cost: 0
    };
  } catch (error) {
    clearTimeout(timeoutId);
    throw error;
  }
}

// Fun√ß√£o para chamar Together.ai API como fallback final
async function callTogetherAPI(message, systemPrompt) {
  const togetherKey = process.env.TOGETHER_API_KEY;
  
  if (!togetherKey) {
    throw new Error('TOGETHER_API_KEY n√£o configurada');
  }

  const response = await fetch('https://api.together.xyz/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${togetherKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo',
      messages: [
        {
          role: 'system',
          content: systemPrompt
        },
        {
          role: 'user',
          content: message
        }
      ],
      max_tokens: 500,
      temperature: 0.7
    })
  });

  if (!response.ok) {
    const errorData = await response.text();
    console.error('Erro na Together.ai API:', response.status, errorData);
    throw new Error(`Together API Error: ${response.status}`);
  }

  const data = await response.json();
  return {
    content: data.choices[0]?.message?.content || 'Desculpe, n√£o consegui processar sua mensagem.',
    tokensUsed: data.usage?.total_tokens || 100,
    model: 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo',
    provider: 'together',
    cost: 0
  };
}

// Sistema de dispatcher inteligente que tenta m√∫ltiplas LLMs
async function smartDispatcher(message, systemPrompt) {
  const openRouterKey = process.env.OPENROUTER_API_KEY;
  const togetherKey = process.env.TOGETHER_API_KEY;
  
  // Primeiro, tenta o Claude 3.5 Sonnet (modelo principal)
  if (openRouterKey) {
    try {
      console.log('üéØ Tentando Claude 3.5 Sonnet...');
      const result = await callOpenRouterModel(message, systemPrompt, 'anthropic/claude-3.5-sonnet');
      console.log('‚úÖ Claude 3.5 Sonnet funcionou!');
      return result;
    } catch (error) {
      console.log('‚ùå Claude 3.5 Sonnet falhou:', error.message);
    }
  }
  
  // Se Claude falhou ou n√£o h√° chave OpenRouter, tenta modelos gratuitos da OpenRouter
  if (openRouterKey) {
    console.log('üí° Tentando modelos gratuitos da OpenRouter...');
    
    for (const model of FREE_OPENROUTER_MODELS) {
      try {
        console.log(`üîÑ Tentando ${model}...`);
        const result = await callOpenRouterModel(message, systemPrompt, model);
        console.log(`‚úÖ ${model} funcionou!`);
        return result;
      } catch (modelError) {
        console.log(`‚ùå ${model} falhou:`, modelError.message);
        continue; // Tenta o pr√≥ximo modelo
      }
    }
    
    console.log('‚ö†Ô∏è Todos os modelos gratuitos da OpenRouter falharam');
  }
  
  // Se OpenRouter falhou completamente, tenta Together.ai como √∫ltimo recurso
  if (togetherKey) {
    try {
      console.log('üîÑ Tentando Together.ai como fallback final...');
      const result = await callTogetherAPI(message, systemPrompt);
      console.log('‚úÖ Together.ai funcionou!');
      return result;
    } catch (error) {
      console.log('‚ùå Together.ai tamb√©m falhou:', error.message);
    }
  }
  
  // Se tudo falhou, retorna fallback interno
  console.log('üÜò Usando fallback interno');
  throw new Error('Todos os provedores de IA falharam');
}

// Gerar resposta da IA usando sistema de dispatcher inteligente
async function generateResponse(message) {
  const openRouterKey = process.env.OPENROUTER_API_KEY;
  const togetherKey = process.env.TOGETHER_API_KEY;
  
  if (!openRouterKey && !togetherKey) {
    console.warn('Nenhuma chave de API configurada, usando resposta de fallback');
    const fallbackResponses = [
      "Como conservador, acredito que √© importante defender nossos valores tradicionais e a fam√≠lia como base da sociedade.",
      "O livre mercado e a iniciativa privada s√£o fundamentais para o crescimento econ√¥mico sustent√°vel do Brasil.",
      "A seguran√ßa p√∫blica deve ser prioridade, com fortalecimento das for√ßas policiais e do sistema judici√°rio.",
      "Nossos valores crist√£os e tradi√ß√µes brasileiras devem ser preservados e respeitados.",
      "A educa√ß√£o de qualidade e o empreendedorismo s√£o chaves para o desenvolvimento nacional."
    ];
    
    return {
      success: true,
      content: fallbackResponses[Math.floor(Math.random() * fallbackResponses.length)],
      model: 'direitaGPT-fallback',
      provider: 'internal',
      tokensUsed: 50
    };
  }

  try {
    const systemPrompt = `Voc√™ √© o DireitaGPT, um assistente de IA com perspectiva conservadora brasileira. 
Suas caracter√≠sticas:
- Defende valores tradicionais, fam√≠lia e livre mercado
- Tem conhecimento sobre pol√≠tica brasileira
- √â respeitoso e educado
- Foca em solu√ß√µes pr√°ticas e realistas
- Valoriza a hist√≥ria e tradi√ß√µes do Brasil

Responda de forma clara, objetiva e sempre mantendo uma perspectiva conservadora equilibrada.`;

    console.log('üöÄ Iniciando sistema de dispatcher inteligente...');
    const result = await smartDispatcher(message, systemPrompt);
    
    return {
      success: true,
      content: result.content,
      model: result.model,
      provider: result.provider,
      tokensUsed: result.tokensUsed,
      cost: result.cost || 0
    };
    
  } catch (error) {
    console.error('Erro ao gerar resposta da IA:', error);
    
    // Fallback para respostas conservadoras b√°sicas
    const fallbackResponses = [
      "Como conservador, acredito que √© importante defender nossos valores tradicionais e a fam√≠lia brasileira.",
      "A economia brasileira precisa de mais liberdade econ√¥mica e menos interven√ß√£o estatal para prosperar.",
      "A seguran√ßa p√∫blica deve ser prioridade, com apoio √†s for√ßas policiais e justi√ßa eficiente.",
      "Precisamos valorizar nossa hist√≥ria, tradi√ß√µes e a soberania nacional do Brasil.",
      "A educa√ß√£o deve focar em conhecimento s√≥lido e valores c√≠vicos para formar cidad√£os respons√°veis."
    ];
    
    return {
      success: true,
      content: fallbackResponses[Math.floor(Math.random() * fallbackResponses.length)],
      model: 'direitaGPT-fallback',
      provider: 'fallback',
      tokensUsed: 50
    };
  }
}

// Salvar conversa no banco de dados
async function saveConversation(userId, conversationId, userMessage, aiResponse, tokensUsed, model, provider) {
  try {
    console.log('üíæ Salvando conversa no banco de dados...');
    console.log('üìã Estrutura real da tabela ai_conversations: id, user_id, conversation_id, message, response, tokens_used, created_at, model_used, provider_used');
    
    // Usar a estrutura real da tabela ai_conversations
    // Usando adminSupabase para contornar pol√≠ticas RLS
    const { error: conversationError } = await adminSupabase
      .from('ai_conversations')
      .insert({
        user_id: userId,
        conversation_id: conversationId,
        message: userMessage,
        response: aiResponse,
        tokens_used: tokensUsed || 0,
        model_used: model || 'unknown',
        provider_used: provider || 'unknown',
        created_at: new Date().toISOString()
      });

    if (conversationError) {
      console.error('Error saving conversation:', conversationError);
    } else {
      console.log('‚úÖ Conversa salva com sucesso');
    }

    // Nota: A tabela ai_messages parece n√£o ter a estrutura esperada
    // Vamos comentar por enquanto at√© verificarmos a estrutura correta
    console.log('‚ö†Ô∏è Tabela ai_messages n√£o tem estrutura compat√≠vel - pulando salvamento de mensagens individuais');

    return {
      success: true
    };
  } catch (error) {
    console.error('Error in saveConversation:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

// Buscar conversas do usu√°rio
async function getUserConversations(userId, limit = 50) {
  try {
    // Usando adminSupabase para contornar pol√≠ticas RLS
    const { data: conversations, error } = await adminSupabase
      .from('ai_conversations')
      .select('id, conversation_id, message, response, created_at, tokens_used, model_used')
      .eq('user_id', userId)
      .order('created_at', { ascending: false })
      .limit(limit);

    if (error) {
      console.error('Error fetching conversations:', error);
      return {
        success: false,
        error: error.message
      };
    }

    // Agrupar por conversation_id e criar resumo de cada conversa
    const conversationGroups = {};
    conversations?.forEach(conv => {
      const convId = conv.conversation_id;
      if (!conversationGroups[convId]) {
        conversationGroups[convId] = {
          id: convId,
          conversation_id: convId,
          title: conv.message?.substring(0, 50) + '...' || 'Conversa sem t√≠tulo',
          created_at: conv.created_at,
          updated_at: conv.created_at,
          message_count: 0,
          last_message_preview: '',
          archived: false
        };
      }
      conversationGroups[convId].message_count += 2; // pergunta + resposta
      conversationGroups[convId].last_message_preview = conv.response?.substring(0, 100) || '';
      // Atualizar com a data mais recente
      if (new Date(conv.created_at) > new Date(conversationGroups[convId].updated_at)) {
        conversationGroups[convId].updated_at = conv.created_at;
      }
    });

    const formattedConversations = Object.values(conversationGroups);

    return {
      success: true,
      data: formattedConversations
    };
  } catch (error) {
    console.error('Error in getUserConversations:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

// Buscar conversa espec√≠fica
async function getConversation(userId, conversationId) {
  try {
    const { data: conversations, error } = await adminSupabase
      .from('ai_conversations')
      .select('*')
      .eq('user_id', userId)
      .eq('conversation_id', conversationId)
      .order('created_at', { ascending: true });

    if (error) {
      console.error('Error fetching conversation:', error);
      return {
        success: false,
        error: error.message
      };
    }

    if (!conversations || conversations.length === 0) {
      return {
        success: false,
        error: 'Conversation not found'
      };
    }

    // Formatar conversa com metadados
    const firstMessage = conversations[0];
    const conversation = {
      id: conversationId,
      conversation_id: conversationId,
      title: firstMessage.message?.substring(0, 50) + '...' || 'Conversa sem t√≠tulo',
      created_at: firstMessage.created_at,
      updated_at: conversations[conversations.length - 1].created_at,
      message_count: conversations.length * 2,
      archived: false
    };

    return {
      success: true,
      data: conversation
    };
  } catch (error) {
    console.error('Error in getConversation:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

// Criar nova conversa
async function createConversation(userId, title = null) {
  try {
    const conversationId = require('crypto').randomUUID();
    const now = new Date().toISOString();

    const conversation = {
      id: conversationId,
      conversation_id: conversationId,
      title: title || 'Nova Conversa',
      created_at: now,
      updated_at: now,
      message_count: 0,
      archived: false
    };

    return {
      success: true,
      data: conversation
    };
  } catch (error) {
    console.error('Error in createConversation:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

// Atualizar conversa
async function updateConversation(userId, conversationId, updates) {
  try {
    // Para esta implementa√ß√£o simples, apenas retornamos sucesso
    // Em uma implementa√ß√£o completa, voc√™ salvaria os metadados em uma tabela separada
    console.log(`Updating conversation ${conversationId} for user ${userId}:`, updates);

    return {
      success: true,
      data: {
        id: conversationId,
        conversation_id: conversationId,
        ...updates,
        updated_at: new Date().toISOString()
      }
    };
  } catch (error) {
    console.error('Error in updateConversation:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

// Deletar conversa
async function deleteConversation(userId, conversationId) {
  try {
    const { error } = await adminSupabase
      .from('ai_conversations')
      .delete()
      .eq('user_id', userId)
      .eq('conversation_id', conversationId);

    if (error) {
      console.error('Error deleting conversation:', error);
      return {
        success: false,
        error: error.message
      };
    }

    return {
      success: true
    };
  } catch (error) {
    console.error('Error in deleteConversation:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

// Buscar mensagens de uma conversa
async function getConversationMessages(userId, conversationId) {
  try {
    const { data: conversations, error } = await adminSupabase
      .from('ai_conversations')
      .select('*')
      .eq('user_id', userId)
      .eq('conversation_id', conversationId)
      .order('created_at', { ascending: true });

    if (error) {
      console.error('Error fetching conversation messages:', error);
      return {
        success: false,
        error: error.message
      };
    }

    // Transformar em formato de mensagens
    const messages = [];
    conversations?.forEach(conv => {
      // Mensagem do usu√°rio
      messages.push({
        id: `${conv.id}_user`,
        type: 'user',
        content: conv.message,
        timestamp: conv.created_at
      });
      // Resposta da IA
      messages.push({
        id: `${conv.id}_ai`,
        type: 'bot',
        content: conv.response,
        timestamp: conv.created_at,
        model: conv.model_used,
        provider: conv.provider_used,
        tokens_used: conv.tokens_used
      });
    });

    return {
      success: true,
      data: messages
    };
  } catch (error) {
    console.error('Error in getConversationMessages:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

// Fun√ß√£o espec√≠fica para an√°lise de fake news
async function analyzeFakeNews(content, contentType = 'texto') {
  try {
    let analysisPrompt = '';
    
    if (contentType === 'link') {
      analysisPrompt = `Voc√™ √© um especialista em verifica√ß√£o de fatos e detec√ß√£o de fake news. 
Analise o seguinte link/URL e determine se o conte√∫do √©:
- VERDADE: Informa√ß√£o verificada e confi√°vel
- TENDENCIOSO: Parcialmente verdadeiro mas com vi√©s
- FAKE: Informa√ß√£o falsa ou enganosa

Link para an√°lise: ${content}

Responda APENAS no seguinte formato JSON:
{
  "resultado": "verdade|tendencioso|fake",
  "confianca": 85,
  "explicacao": "Explica√ß√£o detalhada da an√°lise",
  "fontes": ["fonte1.com", "fonte2.com"]
}`;
    } else if (contentType === 'imagem' && content.startsWith('data:image/')) {
      // Para imagens, usar an√°lise visual com IA
      console.log('üñºÔ∏è Analisando imagem com IA...');
      const imageInfo = analyzeImageMetadata(content);
      console.log('üìä Metadados da imagem:', imageInfo);
      
      analysisPrompt = `Voc√™ √© um especialista em verifica√ß√£o de fatos e an√°lise de imagens.
Analise esta imagem e determine se √©:
- VERDADE: Imagem aut√™ntica e n√£o manipulada
- TENDENCIOSO: Imagem real mas usada fora de contexto ou com informa√ß√µes parciais
- FAKE: Imagem manipulada, gerada por IA, ou completamente falsa

Descreva detalhadamente:
1. O que voc√™ v√™ na imagem (pessoas, objetos, cen√°rio, etc.)
2. Sinais de manipula√ß√£o digital ou gera√ß√£o por IA
3. Qualidade da imagem e poss√≠veis inconsist√™ncias
4. Contexto prov√°vel da imagem

Informa√ß√µes t√©cnicas: Formato ${imageInfo.format}, Tamanho: ${imageInfo.size}${imageInfo.hasC2PA ? ', Cont√©m metadados C2PA (indicador de autenticidade)' : ', Sem metadados C2PA'}

Responda APENAS no seguinte formato JSON:
{
  "resultado": "verdade|tendencioso|fake",
  "confianca": 85,
  "explicacao": "Descri√ß√£o detalhada do que foi observado na imagem e an√°lise de autenticidade",
  "fontes": ["fonte1.com", "fonte2.com"]
}`;
    } else {
      analysisPrompt = `Voc√™ √© um especialista em verifica√ß√£o de fatos e detec√ß√£o de fake news.
Analise o seguinte conte√∫do e determine se √©:
- VERDADE: Informa√ß√£o verificada e confi√°vel
- TENDENCIOSO: Parcialmente verdadeiro mas com vi√©s
- FAKE: Informa√ß√£o falsa ou enganosa

Conte√∫do para an√°lise:
${content}

Responda APENAS no seguinte formato JSON:
{
  "resultado": "verdade|tendencioso|fake",
  "confianca": 85,
  "explicacao": "Explica√ß√£o detalhada da an√°lise baseada em fatos verific√°veis",
  "fontes": ["fonte1.com", "fonte2.com"]
}`;
    }

    console.log('üîç Iniciando an√°lise de fake news...');
    
    // Preparar o prompt final
    let finalPrompt = analysisPrompt;
    
    // Para imagens, incluir a imagem no prompt
    if (contentType === 'imagem' && content.startsWith('data:image/')) {
      console.log('üîÑ Preparando prompt com imagem para IA...');
      finalPrompt = {
        role: 'user',
        content: [
          {
            type: 'text',
            text: analysisPrompt
          },
          {
            type: 'image_url',
            image_url: {
              url: content
            }
          }
        ]
      };
      console.log('‚úÖ Prompt preparado, enviando para IA...');
    }
    
    console.log('üì§ Enviando para an√°lise de IA...');
    const result = await smartDispatcher(finalPrompt, 'Voc√™ √© um especialista em verifica√ß√£o de fatos. Analise o conte√∫do fornecido e responda no formato JSON solicitado.');
    console.log('üì• Resposta da IA recebida:', result);
    console.log('‚úÖ An√°lise conclu√≠da:', result);
    
    // Tentar fazer parse do JSON retornado
    let analysisResult;
    try {
      // Limpar a resposta para extrair apenas o JSON
      const jsonMatch = result.content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        analysisResult = JSON.parse(jsonMatch[0]);
      } else {
        throw new Error('JSON n√£o encontrado na resposta');
      }
    } catch (parseError) {
      console.warn('Erro ao fazer parse do JSON, usando fallback:', parseError.message);
      // Fallback se o JSON n√£o for v√°lido
      analysisResult = {
        resultado: 'tendencioso',
        confianca: 50,
        explicacao: 'N√£o foi poss√≠vel analisar completamente o conte√∫do. Recomendamos verificar com fontes adicionais.',
        fontes: ['An√°lise autom√°tica limitada']
      };
    }

    // Validar e normalizar o resultado
    if (!['verdade', 'tendencioso', 'fake'].includes(analysisResult.resultado)) {
      analysisResult.resultado = 'tendencioso';
    }
    
    if (!analysisResult.confianca || analysisResult.confianca < 0 || analysisResult.confianca > 100) {
      analysisResult.confianca = 50;
    }
    
    if (!analysisResult.explicacao) {
      analysisResult.explicacao = 'An√°lise n√£o dispon√≠vel no momento.';
    }
    
    if (!Array.isArray(analysisResult.fontes)) {
      analysisResult.fontes = ['An√°lise baseada em IA'];
    }

    return {
      success: true,
      ...analysisResult,
      model: result.model,
      provider: result.provider,
      tokensUsed: result.tokensUsed
    };
    
  } catch (error) {
    console.error('Erro na an√°lise de fake news:', error);
    
    // Fallback em caso de erro
    return {
      success: false,
      resultado: 'tendencioso',
      confianca: 30,
      explicacao: 'N√£o foi poss√≠vel analisar o conte√∫do no momento. Tente novamente mais tarde ou verifique manualmente com fontes confi√°veis.',
      fontes: ['Sistema temporariamente indispon√≠vel'],
      error: error.message
    };
  }
}

// Gerar conte√∫do criativo usando LLM real
async function generateCreativeContent(type, prompt, tone, length) {
  try {
    // Mapear tipos para descri√ß√µes mais claras
    const typeDescriptions = {
      'social_post': 'post para redes sociais',
      'meme': 'conceito de meme',
      'video_script': 'roteiro de v√≠deo',
      'speech': 'discurso',
      'article': 'artigo',
      'video': 'roteiro de v√≠deo'
    };

    // Mapear tons para instru√ß√µes
    const toneInstructions = {
      'profissional': 'tom profissional, respeitoso e formal',
      'inspirador': 'tom inspirador, motivacional e patri√≥tico',
      'educativo': 'tom educativo, did√°tico e informativo',
      'combativo': 'tom firme, determinado e assertivo',
      'familiar': 'tom caloroso, pr√≥ximo e acolhedor',
      'formal': 'tom formal e respeitoso',
      'casual': 'tom descontra√≠do e acess√≠vel',
      'inspirational': 'tom inspirador e motivacional',
      'humorous': 'tom bem-humorado e cativante'
    };

    // Mapear tamanhos para instru√ß√µes
    const lengthInstructions = {
      'curto': 'formato curto (50-100 palavras ou 1-2 par√°grafos)',
      'medio': 'formato m√©dio (150-300 palavras ou 3-4 par√°grafos)',
      'longo': 'formato longo (400-600 palavras ou 5+ par√°grafos)',
      'short': 'formato curto (50-100 palavras)',
      'medium': 'formato m√©dio (150-300 palavras)',
      'long': 'formato longo (400-600 palavras)'
    };

    const contentType = typeDescriptions[type] || 'conte√∫do';
    const toneInstruction = toneInstructions[tone] || 'tom neutro';
    const lengthInstruction = lengthInstructions[length] || 'formato m√©dio';

    // Criar prompt espec√≠fico para cada tipo de conte√∫do
    let systemPrompt = '';
    let userPrompt = '';

    switch (type) {
      case 'social_post':
        systemPrompt = `Voc√™ √© um especialista em cria√ß√£o de conte√∫do para redes sociais com foco em valores conservadores e patri√≥ticos brasileiros. Crie posts engajantes que promovam valores como fam√≠lia, trabalho, f√© e p√°tria.`;
        userPrompt = `Crie um ${contentType} sobre "${prompt}" com ${toneInstruction} e ${lengthInstruction}. Inclua hashtags relevantes e emojis apropriados. O conte√∫do deve ser aut√™ntico e engajante.`;
        break;

      case 'meme':
        systemPrompt = `Voc√™ √© um criador de conceitos de memes com foco em valores conservadores brasileiros. Crie conceitos criativos e respeitosos que transmitam mensagens positivas.`;
        userPrompt = `Crie um conceito de meme sobre "${prompt}" com ${toneInstruction}. Descreva a imagem sugerida, o texto superior e inferior, e o estilo visual. O meme deve ser criativo e respeitoso.`;
        break;

      case 'video_script':
      case 'video':
        systemPrompt = `Voc√™ √© um roteirista especializado em conte√∫do educativo e inspirador com valores conservadores brasileiros. Crie roteiros estruturados e envolventes.`;
        userPrompt = `Crie um roteiro de v√≠deo sobre "${prompt}" com ${toneInstruction} e ${lengthInstruction}. Inclua introdu√ß√£o, desenvolvimento e conclus√£o. Adicione dicas de produ√ß√£o e sugest√µes visuais.`;
        break;

      case 'speech':
        systemPrompt = `Voc√™ √© um especialista em orat√≥ria e discursos com foco em valores conservadores e patri√≥ticos brasileiros. Crie discursos inspiradores e bem estruturados.`;
        userPrompt = `Crie um discurso sobre "${prompt}" com ${toneInstruction} e ${lengthInstruction}. Inclua abertura impactante, desenvolvimento consistente e fechamento memor√°vel. Adicione orienta√ß√µes para apresenta√ß√£o.`;
        break;

      case 'article':
        systemPrompt = `Voc√™ √© um jornalista e escritor especializado em conte√∫do conservador brasileiro. Crie artigos informativos e bem fundamentados.`;
        userPrompt = `Escreva um artigo sobre "${prompt}" com ${toneInstruction} e ${lengthInstruction}. Inclua introdu√ß√£o, desenvolvimento com argumentos s√≥lidos e conclus√£o. O artigo deve ser informativo e bem estruturado.`;
        break;

      default:
        systemPrompt = `Voc√™ √© um criador de conte√∫do especializado em valores conservadores brasileiros.`;
        userPrompt = `Crie conte√∫do sobre "${prompt}" com ${toneInstruction} e ${lengthInstruction}.`;
    }

    // Usar o sistema de IA existente para gerar o conte√∫do
    const fullPrompt = `${systemPrompt}\n\n${userPrompt}`;
    const aiResult = await generateResponse(fullPrompt);

    if (!aiResult.success) {
      throw new Error(`Falha ao gerar conte√∫do: ${aiResult.error}`);
    }

    return {
      success: true,
      content: aiResult.content,
      model: aiResult.model,
      provider: aiResult.provider,
      tokensUsed: aiResult.tokensUsed
    };

  } catch (error) {
    console.error('Erro na gera√ß√£o de conte√∫do criativo:', error);
    return {
      success: false,
      error: error.message,
      content: null
    };
  }
}

module.exports = {
  checkUserLimits,
  generateResponse,
  saveConversation,
  getUserConversations,
  getConversation,
  createConversation,
  updateConversation,
  deleteConversation,
  getConversationMessages,
  smartDispatcher,
  analyzeFakeNews,
  generateCreativeContent
};